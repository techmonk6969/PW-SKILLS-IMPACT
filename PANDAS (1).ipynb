{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54cfb1c8-be7c-4419-8f22-b60d30f0cd4c",
   "metadata": {},
   "source": [
    "Q1. Write a code to print the data present in the second row of the dataframe, df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7483619-8cfb-494a-9eb5-0c210b034893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "course_name    Machine Learning\n",
      "duration                      3\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "course_name = ['Data Science', 'Machine Learning', 'Big Data', 'Data Engineer']\n",
    "duration = [2, 3, 6, 4]\n",
    "\n",
    "df = pd.DataFrame(data={'course_name': course_name, 'duration': duration})\n",
    "\n",
    "# Code to print the data present in the second row\n",
    "second_row_data = df.iloc[1]\n",
    "print(second_row_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e159f7-bacd-4c6b-885d-afb436164e12",
   "metadata": {},
   "source": [
    "Q2. What is the difference between the functions loc and iloc in pandas.DataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32039e0b-2558-46fb-99db-4005b6a2b967",
   "metadata": {},
   "source": [
    "loc:\n",
    "\n",
    "loc is label-based indexing, which means you can access the data using the labels of the rows and columns.\n",
    "It is used with the actual labels of the rows and columns.\n",
    "The syntax is df.loc[row_label, column_label].\n",
    "It includes the end label in the range when slicing (similar to regular Python slicing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9715029f-a176-4c79-9f23-528f5d8fcd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting data from the DataFrame using loc\n",
    "df.loc[1, 'course_name']  # Access the value in the 'course_name' column of the row with label 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0777c1-8426-4331-ba71-ceebe6e9cd4c",
   "metadata": {},
   "source": [
    "iloc:\n",
    "\n",
    "iloc is integer-location based indexing, which means you can access the data using integer indices of the rows and columns.\n",
    "It is used with integer positions to select data.\n",
    "The syntax is df.iloc[row_index, column_index].\n",
    "It excludes the end index in the range when slicing (similar to Python list slicing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23827ab-725c-4b61-befc-70b7d4f34c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting data from the DataFrame using iloc\n",
    "df.iloc[1, 0]  # Access the value in the first column of the second row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f513ef-b222-4f21-bba8-f97b92b67d7b",
   "metadata": {},
   "source": [
    "Q3. Reindex the given dataframe using a variable, reindex = [3,0,1,2] and store it in the variable, new_df\n",
    "then find the output for both new_df.loc[2] and new_df.iloc[2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32879119-4cc1-4568-b467-28359f5542e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result using loc:\n",
      "course_name    Big Data\n",
      "duration              6\n",
      "Name: 2, dtype: object\n",
      "\n",
      "Result using iloc:\n",
      "course_name    Machine Learning\n",
      "duration                      3\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "course_name = ['Data Science', 'Machine Learning', 'Big Data', 'Data Engineer']\n",
    "duration = [2, 3, 6, 4]\n",
    "\n",
    "df = pd.DataFrame(data={'course_name': course_name, 'duration': duration})\n",
    "\n",
    "# Reindexing the DataFrame using the given order\n",
    "reindex_order = [3, 0, 1, 2]\n",
    "new_df = df.reindex(reindex_order)\n",
    "\n",
    "# Accessing the data using loc and iloc\n",
    "loc_result = new_df.loc[2]\n",
    "iloc_result = new_df.iloc[2]\n",
    "\n",
    "# Printing the results\n",
    "print(\"Result using loc:\")\n",
    "print(loc_result)\n",
    "\n",
    "print(\"\\nResult using iloc:\")\n",
    "print(iloc_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a98f6ad-8d46-43b7-9653-4f6ee5cd63d3",
   "metadata": {},
   "source": [
    "Q4. Write a code to find the following statistical measurements for the above dataframe df1:\n",
    "(i) mean of each and every column present in the dataframe.\n",
    "(ii) standard deviation of column, ‘column_2’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b80564e-cb7a-474b-8c41-47b26e39a8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of each column:\n",
      "column_1    0.325106\n",
      "column_2    0.397705\n",
      "column_3    0.409136\n",
      "column_4    0.579257\n",
      "column_5    0.618643\n",
      "column_6    0.797573\n",
      "dtype: float64\n",
      "\n",
      "Standard deviation of 'column_2':\n",
      "0.2974904225052703\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# Creating a dataframe\n",
    "df1 = pd.DataFrame(np.random.rand(6, 6), columns=columns, index=indices)\n",
    "\n",
    "# (i) Mean of each and every column\n",
    "column_means = df1.mean()\n",
    "print(\"Mean of each column:\")\n",
    "print(column_means)\n",
    "\n",
    "# (ii) Standard deviation of column 'column_2'\n",
    "std_dev_column_2 = df1['column_2'].std()\n",
    "print(\"\\nStandard deviation of 'column_2':\")\n",
    "print(std_dev_column_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6da86b2-bb2d-4cab-9b91-d1f461476459",
   "metadata": {},
   "source": [
    "Q5. Replace the data present in the second row of column, ‘column_2’ by a string variable then find the\n",
    "mean of column, column_2.\n",
    "If you are getting errors in executing it then explain why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e428f61-6dd5-4521-97f0-c189c5a9c861",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m df1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn_2\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msome_string\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Finding the mean of 'column_2'\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m mean_column_2 \u001b[38;5;241m=\u001b[39m \u001b[43mdf1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcolumn_2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn_2\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m after replacement:\u001b[39m\u001b[38;5;124m\"\u001b[39m, mean_column_2)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11847\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11829\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[1;32m  11830\u001b[0m     _num_doc,\n\u001b[1;32m  11831\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the mean of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11845\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11846\u001b[0m ):\n\u001b[0;32m> 11847\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11401\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  11394\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  11395\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m lib\u001b[38;5;241m.\u001b[39mNoDefault \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mno_default,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11399\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11400\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 11401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11402\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m  11403\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11353\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11343\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m  11344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the level keyword in DataFrame and Series aggregations is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m  11345\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will be removed in a future version. Use groupby \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11348\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m  11349\u001b[0m     )\n\u001b[1;32m  11350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_by_level(\n\u001b[1;32m  11351\u001b[0m         name, axis\u001b[38;5;241m=\u001b[39maxis, level\u001b[38;5;241m=\u001b[39mlevel, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[1;32m  11352\u001b[0m     )\n\u001b[0;32m> 11353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[1;32m  11355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/series.py:4816\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   4813\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not implement \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4814\u001b[0m     )\n\u001b[1;32m   4815\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 4816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:93\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 93\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:155\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    153\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:418\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 418\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[1;32m    421\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:706\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    703\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[1;32m    705\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[0;32m--> 706\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_sum\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    709\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:48\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# Creating a dataframe\n",
    "df1 = pd.DataFrame(np.random.rand(6, 6), columns=columns, index=indices)\n",
    "\n",
    "# Attempting to replace the data in the second row of 'column_2' with a string\n",
    "df1['column_2'][2] = 'some_string'\n",
    "\n",
    "# Finding the mean of 'column_2'\n",
    "mean_column_2 = df1['column_2'].mean()\n",
    "print(\"Mean of 'column_2' after replacement:\", mean_column_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91b6d17-e57f-4e1b-b05b-90e07e3b57ef",
   "metadata": {},
   "source": [
    "Executing this code will likely raise a TypeError because pandas will attempt to maintain a consistent data type within each column, and it cannot convert a string into a numeric type automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e33ba00-3211-4e5d-bd37-4f60f3c60807",
   "metadata": {},
   "source": [
    "Q6. What do you understand about the windows function in pandas and list the types of windows\n",
    "functions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb06c33-7543-43ce-9dd3-38ac2290d218",
   "metadata": {},
   "source": [
    "In pandas, the term \"window functions\" refers to a family of functions that operate on a specific subset of data defined by a window, which is typically a moving or expanding window of data points. These functions are useful for analyzing and computing metrics over a rolling or expanding set of data within a DataFrame or a Series.\n",
    "\n",
    "The key concept is that these functions operate on a specified window of data points rather than the entire dataset. This is particularly useful for time-series data or other ordered data where you want to compute statistics over a moving or expanding window.\n",
    "\n",
    "Here are some types of window functions available in pandas:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8b9062-5218-4db2-bf77-f65e1a498502",
   "metadata": {},
   "source": [
    "Rolling Functions:\n",
    "\n",
    "rolling() function is used to create a Rolling object, and then you can apply various aggregation functions on that object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d4f390-482e-46bf-894c-fec5af81d6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['column'].rolling(window=3).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d5c54b-f5b2-4b5f-b990-68f90176d349",
   "metadata": {},
   "source": [
    "Expanding Functions:\n",
    "\n",
    "expanding() function computes the expanding window statistic, where the window size starts from the beginning and grows until the current point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2a8c1b-a07f-4804-b2e0-31f185d5d1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['column'].expanding().mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e0f2ac-78e0-40e2-9a4b-31981ab75d5e",
   "metadata": {},
   "source": [
    "Q7. Write a code to print only the current month and year at the time of answering this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d1ea40e-0032-4bb8-b0e1-bd9504cacec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current month and year: February 2024\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = datetime.now()\n",
    "\n",
    "# Format to display only month and year\n",
    "current_month_year = current_datetime.strftime(\"%B %Y\")\n",
    "\n",
    "# Print the result\n",
    "print(\"Current month and year:\", current_month_year)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51af543-655f-4579-ba37-5e55acb02266",
   "metadata": {},
   "source": [
    "Q8. Write a Python program that takes in two dates as input (in the format YYYY-MM-DD) and\n",
    "calculates the difference between them in days, hours, and minutes using Pandas time delta. The\n",
    "program should prompt the user to enter the dates and display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38caed48-852a-4261-84e6-f8b2d96b8756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to calculate the difference between two dates\n",
    "def calculate_time_difference(date1, date2):\n",
    "    # Convert input strings to datetime objects\n",
    "    datetime1 = pd.to_datetime(date1, format='%Y-%m-%d')\n",
    "    datetime2 = pd.to_datetime(date2, format='%Y-%m-%d')\n",
    "\n",
    "    # Calculate the time difference\n",
    "    time_difference = datetime2 - datetime1\n",
    "\n",
    "    # Extract days, hours, and minutes\n",
    "    days_difference = time_difference.days\n",
    "    hours_difference, remainder = divmod(time_difference.seconds, 3600)\n",
    "    minutes_difference = remainder // 60\n",
    "\n",
    "    return days_difference, hours_difference, minutes_difference\n",
    "\n",
    "# Prompt the user to enter two dates\n",
    "date_input1 = input(\"Enter the first date (YYYY-MM-DD): \")\n",
    "date_input2 = input(\"Enter the second date (YYYY-MM-DD): \")\n",
    "\n",
    "# Calculate the time difference\n",
    "days_diff, hours_diff, minutes_diff = calculate_time_difference(date_input1, date_input2)\n",
    "\n",
    "# Display the result\n",
    "print(f\"\\nTime difference between {date_input1} and {date_input2}:\")\n",
    "print(f\"Days: {days_diff} days\")\n",
    "print(f\"Hours: {hours_diff} hours\")\n",
    "print(f\"Minutes: {minutes_diff} minutes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75293b04-3c19-4589-b5d1-c2c3b45c9ab0",
   "metadata": {},
   "source": [
    "Q9. Write a Python program that reads a CSV file containing categorical data and converts a specified\n",
    "column to a categorical data type. The program should prompt the user to enter the file path, column\n",
    "name, and category order, and then display the sorted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b4b73f-15ab-4357-b7e4-b1419cecd312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to read CSV file, convert specified column, and display sorted data\n",
    "def convert_and_sort_csv(file_path, column_name, category_order):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Convert the specified column to categorical with specified category order\n",
    "    df[column_name] = pd.Categorical(df[column_name], categories=category_order, ordered=True)\n",
    "\n",
    "    # Sort the DataFrame based on the specified column\n",
    "    df_sorted = df.sort_values(by=[column_name])\n",
    "\n",
    "    # Display the sorted data\n",
    "    print(\"\\nSorted Data:\")\n",
    "    print(df_sorted)\n",
    "\n",
    "# Prompt the user to enter file path, column name, and category order\n",
    "file_path = input(\"Enter the CSV file path: \")\n",
    "column_name = input(\"Enter the column name to convert: \")\n",
    "category_order_input = input(\"Enter the category order (comma-separated): \")\n",
    "\n",
    "# Convert the category order input to a list\n",
    "category_order = category_order_input.split(',')\n",
    "\n",
    "# Call the function to perform the operations\n",
    "convert_and_sort_csv(file_path, column_name, category_order)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb457b04-a289-468e-92ac-5f8009c1fd34",
   "metadata": {},
   "source": [
    "Q10. Write a Python program that reads a CSV file containing sales data for different products and\n",
    "visualizes the data using a stacked bar chart to show the sales of each product category over time. The\n",
    "program should prompt the user to enter the file path and display the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2c3c14-0742-4d93-9167-f1acefde24a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to read CSV file and visualize sales data using a stacked bar chart\n",
    "def visualize_sales_data(file_path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Assuming the CSV contains columns: 'Date', 'Product Category', 'Sales'\n",
    "    # You may need to adjust the column names based on your actual data\n",
    "\n",
    "    # Convert 'Date' column to datetime type\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    # Pivot the DataFrame to create a table suitable for stacked bar chart\n",
    "    pivot_df = df.pivot(index='Date', columns='Product Category', values='Sales').fillna(0)\n",
    "\n",
    "    # Plotting the stacked bar chart\n",
    "    pivot_df.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "    \n",
    "    # Adding labels and title\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Sales')\n",
    "    plt.title('Stacked Bar Chart - Sales Data by Product Category')\n",
    "\n",
    "    # Show the chart\n",
    "    plt.show()\n",
    "\n",
    "# Prompt the user to enter the file path\n",
    "file_path = input(\"Enter the CSV file path: \")\n",
    "\n",
    "# Call the function to visualize the sales data\n",
    "visualize_sales_data(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8c8901-bcf9-4bb9-8a76-dcaf20884989",
   "metadata": {},
   "source": [
    "Q11. You are given a CSV file containing student data that includes the student ID and their test score. Write\n",
    "a Python program that reads the CSV file, calculates the mean, median, and mode of the test scores, and\n",
    "displays the results in a table.\n",
    "The program should do the followingM\n",
    "I Prompt the user to enter the file path of the CSV file containing the student dataR\n",
    "I Read the CSV file into a Pandas DataFrameR\n",
    "I Calculate the mean, median, and mode of the test scores using Pandas toolsR\n",
    "I Display the mean, median, and mode in a table.\n",
    "Assume the CSV file contains the following columnsM\n",
    "I Student ID: The ID of the studentR\n",
    "I Test Score: The score of the student's test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b67b70-188f-4a4e-810b-031f785355a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to calculate mean, median, and mode of test scores and display results\n",
    "def calculate_and_display_statistics(file_path):\n",
    "    # Read the CSV file into a Pandas DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Calculate mean, median, and mode of test scores\n",
    "    mean_score = df['Test Score'].mean()\n",
    "    median_score = df['Test Score'].median()\n",
    "    mode_score = df['Test Score'].mode().iloc[0]  # Mode can have multiple values, selecting the first one\n",
    "\n",
    "    # Create a DataFrame to display the results\n",
    "    result_df = pd.DataFrame({\n",
    "        'Statistic': ['Mean', 'Median', 'Mode'],\n",
    "        'Test Score': [mean_score, median_score, mode_score]\n",
    "    })\n",
    "\n",
    "    # Display the results\n",
    "    print(\"\\nStatistics for Test Scores:\")\n",
    "    print(result_df)\n",
    "\n",
    "# Prompt the user to enter the file path\n",
    "file_path = input(\"Enter the CSV file path containing student data: \")\n",
    "\n",
    "# Call the function to calculate and display statistics\n",
    "calculate_and_display_statistics(file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
